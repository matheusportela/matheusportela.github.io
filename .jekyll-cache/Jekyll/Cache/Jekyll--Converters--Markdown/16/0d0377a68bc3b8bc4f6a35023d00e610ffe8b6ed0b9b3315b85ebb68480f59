I"äF<p>Recentemente, montei um PC novo com a inten√ß√£o de rodar jogos mais pesados, que n√£o podem ser executados no meu laptop, e poder utilizar a sua GPU em algoritmos de Deep Learning. Ap√≥s instalar o <a href="http://releases.ubuntu.com/16.04/">Ubuntu 16.04</a>, a distribui√ß√£o Linux mais simples para iniciar qualquer tipo de trabalho, escolhi utilizar o <a href="https://www.tensorflow.org/">Tensorflow</a> como framework para implementa√ß√£o de algoritmos de ML uma vez que, al√©m de ser desenvolvido em Python, tornou-se o framework mais popular na ind√∫stria. Outra op√ß√£o seria o <a href="http://torch.ch/">Torch</a>, que √© bastante utilizado em trabalhos acad√™micos.</p>

<p><a href="https://www.tensorflow.org/install/install_linux">Instalar o Tensorflow</a> com suporte a GPU √© super simples, trabalho feito em um √∫nico comando:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ pip install tensorflow-gpu
</code></pre></div></div>

<p>Entretanto, para minha surpresa, os pacotes pr√©-compilados do Tensorflow est√£o <em>desatualizados</em>. Embora, o CUDA esteja na vers√£o 9.0 e o cuDNN, na 7.0, o pacote pr√©-compilado do Tensorflow 1.4 requer CUDA 8.0 e cuDNN 6.0. Mais ainda, esse pacote n√£o faz uso dos conjuntos de instru√ß√µes <a href="https://en.wikipedia.org/wiki/SSE4">SSE 4.1 e SSE 4.2</a>, <a href="https://en.wikipedia.org/wiki/Advanced_Vector_Extensions">AVX e AVX2</a> e <a href="https://en.wikipedia.org/wiki/Multiply%E2%80%93accumulate_operation#Fused_multiply%E2%80%93add">FMA</a>, que aceleram a execu√ß√£o de algumas opera√ß√µes na CPU.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>W tensorflow/core/platform/cpu_feature_guard.cc:95] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:95] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:95] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:95] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:95] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
</code></pre></div></div>

<p>Para n√£o desperdi√ßar o potencial da CPU e GPU, <strong>resolvi compilar o Tensorflow a partir do c√≥digo-fonte</strong>. Apesar de poder intimidar √† primeira vista, garanto que n√£o h√° grandes dificuldades e que voc√™ tamb√©m pode faz√™-lo.</p>

<p>Portanto, escrevi esse passo a passo para fins de documenta√ß√£o pr√≥pria, caso precise realizar essa instala√ß√£o novamente no futuro. Disponibilizo os passos aqui para ajudar quem tenha encontrado o mesmo problema na sua m√°quina.</p>

<h1 id="tensorflow-do-c√≥digo-fonte-ao-python">Tensorflow: Do c√≥digo-fonte ao Python</h1>

<h2 id="instalando-drivers-da-gpu">Instalando drivers da GPU</h2>

<p>Antes de mais nada, √© necess√°rio instalar os drivers gr√°ficos da NVIDIA no seu Ubuntu. Para isso, vamos adicionar o PPA que cont√©m esses drivers - que s√£o propriet√°rios.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ sudo add-apt-repository ppa:graphics-drivers/ppa
$ sudo apt update
$ sudo apt upgrade
</code></pre></div></div>

<p>Em seguida, v√° em <code class="highlighter-rouge">System Settings &gt; Software and updates &gt; Aditional drivers</code> e selecione a vers√£o mais recente do driver que houver dispon√≠vel. <a href="http://www.edivaldobrito.com.br/recentes-drivers-graficos-proprietarios-no-ubuntu/">Esse tutorial</a> possui screenshots mostrando exatamente como fazer isso.</p>

<h2 id="instalando-o-ambiente-de-desenvolvimento">Instalando o ambiente de desenvolvimento</h2>

<p>Primeiro, devemos garantir que temos os headers mais atualizados para desenvolver em Linux:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ sudo apt install linux-headers-$(uname -r)
</code></pre></div></div>

<p>Para trabalhar com Python, vamos utilizar o <a href="https://pypi.python.org/pypi/pip">pip</a> como gerenciador de pacotes.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ sudo apt install python-pip python-dev
$ pip install --upgrade pip
</code></pre></div></div>

<p>Al√©m disso, o <a href="https://virtualenv.pypa.io/en/stable/">virtualenv</a> √© extremamente recomend√°vel para isolar depend√™ncias de maneira saud√°vel. Tamb√©m recomendo fortemente o uso do <a href="https://virtualenvwrapper.readthedocs.io/en/latest/">virtualenvwrapper</a>, que facilita o uso do virtualenv.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ pip install virtualenv --user
$ pip install virtualenvwrapper --user
$ source /usr/local/bin/virtualenvwrapper.sh
$ echo "" &gt;&gt; ~/.bashrc
$ echo "# Virtualenv" &gt;&gt; ~/.bashrc
$ echo "source ~/.local/bin/virtualenvwrapper.sh" &gt;&gt; ~/.bashrc
</code></pre></div></div>

<p>Por fim, para quem desejar um interpretador Python um pouco mais amig√°vel e com funcionalidades extras, o <a href="https://ipython.org/">IPython</a> √© a minha sugest√£o.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ sudo apt install ipython ipython-notebook
</code></pre></div></div>

<h2 id="instalando-cuda-e-cudnn">Instalando CUDA e cuDNN</h2>

<p>Com o ambiente instalado, podemos instalar as bibliotecas mais importantes para trabalhar com a GPU: <a href="https://developer.nvidia.com/cuda-toolkit">CUDA</a> - um toolkit para programa√ß√£o em placas gr√°ficas com a linguagem CUDA C - e <a href="https://developer.nvidia.com/cudnn">cuDNN</a> - o framework para acelerar a execu√ß√£o Deep Neural Networks e GPUs da NVIDIA.</p>

<h3 id="instalando-cuda">Instalando CUDA</h3>

<p>Inicialmente, √© necess√°rio fazer o download dos arquivos <code class="highlighter-rouge">.deb</code> do CUDA diretamente do <a href="https://developer.nvidia.com/cuda-downloads">site da NVIDIA</a>.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ cd ~/Downloads/
$ sudo dpkg -i cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64.deb
</code></pre></div></div>

<p>Agora, podemos instalar o CUDA a partir do pr√©-compilado disponibilizado pela NVIDIA.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ sudo apt-key add /var/cuda-repo-9-0-local/7fa2af80.pub
$ sudo apt update
$ sudo apt install cuda
</code></pre></div></div>

<p>Tamb√©m √© necess√°rio configurar duas vari√°veis de ambiente: <code class="highlighter-rouge">PATH</code> e <code class="highlighter-rouge">LD_LIBRARY_PATH</code> com os caminhos de instala√ß√£o do CUDA. Vamos colocar essas informa√ß√µes no <code class="highlighter-rouge">~/.bashrc</code>.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ echo "" &gt;&gt; ~/.bashrc
$ echo "# CUDA" &gt;&gt; ~/.bashrc
$ echo "export PATH=\"\$PATH:/usr/local/cuda-9.0/bin\"" &gt;&gt; ~/.bashrc
$ echo "export LD_LIBRARY_PATH=\"/usr/local/cuda-9.0/lib64\"" &gt;&gt; ~/.bashrc
</code></pre></div></div>

<p>Ap√≥s esses passos, j√° √© poss√≠vel instalar o CUDA toolkit, o √∫ltimo passo necess√°rio para executar o ambiente do CUDA no seu computador:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ sudo apt install nvidia-cuda-toolkit
</code></pre></div></div>

<p>Para testar a instala√ß√£o do CUDA at√© aqui, o comando <code class="highlighter-rouge">nvidia-smi</code> pode ser utilizado. Ele apresenta na tela dados da GPU detectada e v√°rios status, como percentual de mem√≥ria de v√≠deo livre. Caso seja necess√°rio, reinicie o terminal ou o computador para aplicar as altera√ß√µes realizadas nos passos anteriores.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ nvidia-smi
</code></pre></div></div>

<h3 id="instalando-cudnn">Instalando cuDNN</h3>

<p>O processo para instala√ß√£o do cuDNN √© ainda mais f√°cil do que o do CUDA. Come√ßamos baixando tr√™s arquivos <code class="highlighter-rouge">.deb</code> do <a href="https://developer.nvidia.com/rdp/cudnn-download">site da NVIDIA</a>: <code class="highlighter-rouge">libcudnn7_&lt;version&gt;.deb</code>, <code class="highlighter-rouge">libcudnn7-dev_&lt;version&gt;.deb</code> e <code class="highlighter-rouge">libcudnn7-doc_&lt;version&gt;.deb</code>. Note que √© necess√°rio preencher um formul√°rio antes de conseguir baix√°-los.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ cd ~/Downloads/
$ sudo dpkg -i libcudnn7_7.0.4.31-1+cuda9.0_amd64.deb
$ sudo dpkg -i libcudnn7-dev_7.0.4.31-1+cuda9.0_amd64.deb
$ sudo dpkg -i libcudnn7-doc_7.0.4.31-1+cuda9.0_amd64.deb
$ sudo apt install libcupti-dev
</code></pre></div></div>

<p>Pronto!</p>

<p>Para testar a instala√ß√£o, vamos compilar o exemplo de classifica√ß√£o de d√≠gitos com Deep Neural Networks usando a base de dados do <a href="http://yann.lecun.com/exdb/mnist/">MNIST</a>.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ mkdir /tmp/cudnn
$ cd /tmp/cudnn
$ cp -r /usr/src/cudnn_samples_v7/ /tmp/cudnn/
$ cd /tmp/cudnn/cudnn_samples_v7/mnistCUDNN/
$ make clean
$ make
$ ./mnistCUDNN
</code></pre></div></div>

<p>Se tudo der certo, o script deve mostrar uma mensagem de sucesso.</p>

<h2 id="instalando-mkl">Instalando MKL</h2>

<p>Uma das bibliotecas que iremos instalar ser√° a <a href="https://software.intel.com/en-us/mkl">MKL</a>, Math Kernel Library, desenvolvida pela Intel. Segundo a empresa, utilizar tal biblioteca em CPUs da Intel prov√™ um ganho significativo de performance para Deep Neural Networks. A parte boa √© que o Tensorflow integra com a MKL de forma transparente!</p>

<p>Iremos compilar a MKL a partir do c√≥digo-fonte <a href="https://github.com/01org/mkl-dnn.git">dispon√≠vel no GitHub</a>. O processo √© simples e segue o padr√£o <code class="highlighter-rouge">cmake &gt; make &gt; make install</code>.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ sudo apt install git curl cmake doxygen graphviz
$ mkdir ~/git
$ cd git
$ git clone https://github.com/01org/mkl-dnn.git
$ cd mkl-dnn/scripts/
$ ./prepare_mkl.sh
$ mkdir build
$ cd build/
$ cmake ..
$ make
$ make test
$ make doc
$ sudo make install
$ sudo ldconfig
</code></pre></div></div>

<h2 id="instalando-tensorflow">Instalando TensorFlow</h2>

<p>Finalmente chegamos na parte que todos est√°vamos esperando. Compilar o Tensorflow!</p>

<p>Antes de mais nada, vamos criar um virtualenv para o Tensorflow e instalar alguns pacotes necess√°rios para compilar o framework.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ mkvirtualenv tensorflow
$ pip install numpy wheel
</code></pre></div></div>

<p>Tamb√©m vamos instalar o Java 8 da Oracle e o <a href="https://bazel.build/">Bazel</a>, o sistema de build criado pela Google e utilizado pelo Tensorflow.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ sudo add-apt-repository ppa:webupd8team/java
$ sudo apt install oracle-java8-installer
$ echo "deb [arch=amd64] http://storage.googleapis.com/bazel-apt stable jdk1.8" | sudo tee /etc/apt/sources.list.d/bazel.list
$ curl https://bazel.build/bazel-release.pub.gpg | sudo apt-key add -
$ sudo apt update
$ sudo apt install bazel
</code></pre></div></div>

<p>Agora, podemos clonar o reposit√≥rio do Tensorflow para a nossa m√°quina.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ cd ~/git/
$ git clone https://github.com/tensorflow/tensorflow
$ cd tensorflow/
</code></pre></div></div>

<p>Utilizando o <code class="highlighter-rouge">git</code>, podemos fazer o checkout da branch contendo a vers√£o exata do Tensorflow que ser√° instalada ao inv√©s de pegar a vers√£o da branch <code class="highlighter-rouge">master</code>. No caso, iremos com a vers√£o 1.4.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ git checkout r1.4
</code></pre></div></div>

<p>Agora, vamos gerar os arquivos de build a partir do script <code class="highlighter-rouge">configure</code>. <strong>Aten√ß√£o:</strong> nesse momento, voc√™ ter√° que escolher as op√ß√µes de compila√ß√£o que forem adequadas para a sua m√°quina. N√£o se esque√ßa de selecionar o suporte √† GPU!</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ ./configure
</code></pre></div></div>

<p>Esse √© o momento que iremos gerar o pacote do Tensorflow para ser instalado com o pip. Repare que, nesse momento, passamos como argumento as op√ß√µes para suporte de SSE 4.1, SSE 4.2, AVX, AVX2, FMA e MKL.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ bazel build -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --config=mkl //tensorflow/tools/pip_package:build_pip_package
$ bazel-bin/tensorflow/tools/pip_package/build_pip_package ~/git/tensorflow
</code></pre></div></div>

<p>Quando terminarem de serem executados, esses comandos gerar√£o um arquivo do tipo <code class="highlighter-rouge">tensorflow-&lt;version&gt;.whl</code>. Basta instalar esse arquivo na nossa virtualenv para podermos utilizar o Tensorflow.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ pip install --upgrade ~/git/tensorflow/tensorflow-*.whl
</code></pre></div></div>

<p>Vamos aproveitar esse momento para atualizar o <code class="highlighter-rouge">protobuf</code> tamb√©m:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/protobuf-3.0.0b2.post2-cp27-none-linux_x86_64.whl
</code></pre></div></div>

<p><strong>Parab√©ns, voc√™ instalou o Tensorflow a partir do c√≥digo-fonte!</strong>. Voc√™ pode testar sua instala√ß√£o em uma sess√£o do Python que utilize GPU:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s">'/gpu:0'</span><span class="p">):</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">],</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s">'a'</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">],</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s">'b'</span><span class="p">)</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="k">print</span> <span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">c</span><span class="p">))</span>
</code></pre></div></div>

<p>Se tudo der certo, voc√™ ver√° na sa√≠da do seu programa as informa√ß√µes da GPU utilizada. Lembre-se que voc√™ pode utilizar o comando <code class="highlighter-rouge">nvidia-smi</code> para verificar o status da sua placa gr√°fica enquanto estiver executando um script com Tensorflow.</p>

<h1 id="conclus√£o">Conclus√£o</h1>

<p>Ao final desse processo, voc√™ ter√° uma instala√ß√£o fresquinha do Tensorflow com todos os avan√ßos disponibilizados pela NVIDIA e pela Intel na sua m√°quina. Agora, √© hora de botar a m√£o na massa e treinar alguns modelos para fazer o esfor√ßo compensar.</p>

<p>Em um futuro, quero comparar o ganho de desempenho com as otimiza√ß√µes de SEE, AVX, FMA e MKL em rela√ß√£o √† vers√£o padr√£o do Tensorflow dispon√≠vel no <code class="highlighter-rouge">pip</code>.</p>

<p>Espero que voc√™ tenha gostado e at√© a pr√≥xima!</p>
:ET