I"¿<h2 id="undergraduate-thesis-portuguese">Undergraduate Thesis (Portuguese)</h2>

<h3 id="sele√ß√£o-de-comportamentos-em-m√∫ltiplos-agentes-aut√¥nomos-com-aprendizagem-por-refor√ßo-em-ambientes-estoc√°sticos">Sele√ß√£o de Comportamentos em M√∫ltiplos Agentes Aut√¥nomos com Aprendizagem por Refor√ßo em Ambientes Estoc√°sticos</h3>
<p><em>Behavior selection for multiple autonomous agents with reinforcement learning in stochastic environments</em></p>

<p><strong>University of Bras√≠lia</strong></p>

<p><strong>Date:</strong> December 4, 2015</p>

<p><strong>Download:</strong> <a href="http://bdm.unb.br/bitstream/10483/15302/1/2015_MatheusVieiraPortela_tcc.pdf">PDF</a></p>

<p><strong>Abstract (Portuguese):</strong> Agentes inteligentes agem baseados nas suas medi√ß√µes sensoriais a fim de alcan√ßar seus objetivos. Em ambientes din√¢micos, como sistemas multiagentes, agentes devem adaptar seus processos de sele√ß√£o de a√ß√µes de acordo com o estado do sistema mut√°vel, uma vez que comportamentos anteriormente considerados adequados podem tornar-se sub-√≥timos. Tal problema √© ainda maior se o ambiente √© estoc√°stico, for√ßando os agentes a lidarem com incertezas. Esse trabalho prop√µe um algoritmo de aprendizado por refor√ßo para sistemas multiagentes estoc√°sticos, utilizando programa√ß√£o bayesiana para estima√ß√£o de estados e Q-learning com aproxima√ß√£o de fun√ß√µes para prover aos agentes a capacidade de aprender a selecionar os comportamentos mais adequados. Experimentos indicam resultados positivos para a abordagem, onde agentes aprenderam a cooperar, de forma aut√¥noma, em um jogo eletr√¥nico estoc√°stico multiagente.</p>

<h2 id="peer-reviewed-papers">Peer-Reviewed Papers</h2>

<h3 id="state-estimation-and-reinforcement-learning-for-behavior-selection-in-stochastic-multiagent-systems">State Estimation and Reinforcement Learning for Behavior Selection in Stochastic Multiagent Systems</h3>
<p><strong>Authors:</strong>
Matheus Vieira Portela - University of Brasilia, Brasilia, Brazil
Guilherme Novaes Ramos - Department of Computer Science, University of Brasilia, Brasilia, Brazil</p>

<p><strong>Published at:</strong> XIV Brazilian Symposium of Digital Games and Entertainment - 2015 - Proceedings of SBGames 2015 - Computing Track - Short Papers</p>

<p><strong>Publisher:</strong> SBC - Brazilian Computing Society</p>

<p><strong>Publication date:</strong> November 11-13, 2015</p>

<p><strong>Download:</strong> <a href="http://www.sbgames.org/sbgames2015/anaispdf/computacao-short/147936.pdf">PDF</a></p>

<p><strong>Abstract:</strong> Intelligent agents can act based on sensor measurements in order to fulfill their goals. In dynamic systems, agents must adapt its behavior selection processes to reflect the changing system state since behaviors that previously were considered the best choice may become sub-optimal. Multiple agents that co-exist in the environment is one example of such a dynamic system. The problem is even greater when stochastic systems are considered, since the states the agents are actually in are unknown. This work proposes a learning algorithm for stochastic multiagent systems, in which Bayesian programming is used for state estimation and Q-learning provides learning capabilities to the agents. An experimental setup using electronic games is described to evaluate the effectiveness of this approach.</p>

<h3 id="gaze-enhanced-speech-recognition-for-truly-hands-free-and-efficient-text-input-during-hci">Gaze Enhanced Speech Recognition for Truly Hands-Free and Efficient Text Input During HCI</h3>
<p><strong>Authors:</strong>
Matheus Vieira Portela - University of Brasilia, Brasilia, Brazil
David Rozado - CSIRO, QLD, Brisbane, Australia</p>

<p><strong>Published at:</strong> OzCHI ‚Äò14 Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: the Future of Design</p>

<p><strong>Publisher:</strong> ACM <a href="http://dl.acm.org/citation.cfm?id=2686679">http://dl.acm.org/citation.cfm?id=2686679</a></p>

<p><strong>Publication date:</strong> December 2, 2014</p>

<p><strong>Download:</strong> <a href="/assets/files/portela-gaze-enhanced-speech-recognition.pdf">PDF</a></p>

<p><strong>Abstract:</strong> The performance of current speech recognition algorithms is well below that of human speech recognition, with high number of misrecognized words in quiet environments and degrading even further in noisy ones. Therefore, hands-free interaction remains a deeply frustrating experience. In this work, we present an innovative form of correcting misrecognized words during a speech recognition task by using gaze tracking technology in a multimodal approach. We propose to employ the user‚Äôs gaze to point at misrecognized words and select appropriate alternatives. We compare the performance of this multimodal approach with traditional modalities of correcting words: usage of mouse and keyboard and usage of voice alone. The results of the user study show that whereas the proposed system is not as fast as using mouse and keyboard for correction, gaze enhanced correction significantly outperforms voice alone correction and is preferred by the users, offering a truly hands-free means of interaction.</p>

<h2 id="non-peer-reviewed-papers">Non Peer-Reviewed Papers</h2>

<h3 id="bayesian-programming-and-reinforcement-learning-in-stochastic-multiagent-systems">Bayesian Programming and Reinforcement Learning in Stochastic Multiagent Systems</h3>
<p><strong>Authors:</strong>
Matheus Vieira Portela - University of Brasilia, Brasilia, Brazil
Guilherme Novaes Ramos - Department of Computer Science, University of Brasilia, Brasilia, Brazil</p>

<p><strong>Published at:</strong> Graduate School Workshop at the Department of Computer Science - University of Brasilia</p>

<p><strong>Publication date:</strong> October 16-17, 2015</p>

<p><strong>Download:</strong> <a href="/assets/files/wpos-2015.pdf">PDF</a></p>

<p><strong>Abstract:</strong> Intelligent agents act based on sensor measurements in order to fulfill their goals. When the environment is dynamic, such as a multiagent system, agents must adapt its actions selection processes to reflect the ever changing system state since behaviors that previously were considered the best choice may becomes sub-optimal. The problem is even greater when stochasticity is taken into account, since the environment true state is unknown to the agents. This work proposes a learning algorithm for stochastic multiagent systems, in which Bayesian programming is used for state estimation and Q-learning with function approximation provides learning capabilities so as agents can select the appropriate behaviors. An experimental setup to evaluate the effectiveness of this approach using electronic games is described, as well as the preliminary results.</p>
:ET